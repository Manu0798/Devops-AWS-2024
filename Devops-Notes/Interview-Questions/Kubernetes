# What is Kubernetes
-> Kubernetes is a powerful open source Container Orchestration platform which automates the deployment, autoscaling and managing many containers across multiple machines
-> Kubernetes works on cluster modules
-> Kubernetes developed by Google and donted to CNCF at 2014
     [Cloud Native Computing Foundation]


# Why we are using Kubernetes rather than Docker
-> Docker is mainly for packaging and running a single container.
-> Docker is single daemon process. which can cause the single point of failure. if the docker daemon goes down for some reason all the application are down.
-> When we use kubernetes we can overcome above problems because
-> Kubernetes is a powerful open source Container Orchestration platform which automates the deployment, autoscaling and managing many containers across multiple machines
-> As well as we can achive below features when we use kubernetes
   -> Auto Scheduling
   -> Self Healing Capacity
   -> Rollout and Rollback
   -> Autoscaling
   -> Service Discovery
   -> Storage Orchestration
   -> Secret and Configuration Management

# What is Auto Scheduling
-> Kubernetes will provide the Auto Scheduler Option to launch the containers based on our requirments

# Self Healing Capacity
-> If containerized app or application goes down, Kubernetes will redeploy it and retain to the desired state

# Rollout and Rollback
-> If anything goes back, kubernetes will rollback the changes for us

# Autoscaling
-> Autoscaling allow us to automatically scale up and scale down our application based on CPU and Memory Utilization

# Service Discovery
-> Kubernetes will take care the everything about network

# Storage Orchestration
-> Kubernetes will automatically mount the volumes

# Secret and Configuration Management
-> Deploy and update secrets are not expose within stack environment


# What is Docker-Swarm
-> Docker-Swarm is a Container Orchestration tool for clustring and Scheduling the container
-> Docker-Swarm is sutiable for deploy the small application


# What is the Difference between Docker-Swarm and Kubernetes
# Docker-Swarm
-> Docker-Swarm is sutiable for deploy the small application
-> Docker-Swarm supports the manual autoscaling
-> Need Third party tool for monitoring like ELK

# Kubernetes
-> Kubernetes is better sutiable for deploy the large scale application it's offer more scaliablity and networking like policies and huge third party ecosystem support.
-> Kubernetes will support the autoscaling


# What is Kubernetes Architecture.
-> Kubernetes works on cluster module
-> Kubernetes having master node and worker nodes
-> Master nodes will manages the worker nodes
-> Worker nodes will run tasks assign by master nodes
-> We have Kubectl to communicate to our kubernetes cluster
-> kubectl is a command line interface to run the commands on kubernetes cluster
-> we have components in master nodes and worker node
-> In master node we have
    -> API  -> API acts as the gateway for all commands and communications in a Kubernetes cluster.
    -> ETCD -> ETCD act a database in kubernets. It will store all the cluster information such as desired state, current state, and runtime data 
    -> Scheduler -> Scheduler will schedule the pods to worker node based node resources with the help of kubelt which in unschedule request in ETCD. 
    -> Control Manager -> Controller manager continuously monitor the kubernetes cluster through API server. Make Sure desire state maintained
-> In worknode we have
     -> kubelet -> kubelet act as a node agent. It will interact with Container runtime
     -> Container Runtime -> Container Runtime will create and start container inside pod
     -> Kube proxy -> Kube proxy act as a network proxy. it allow the network rules to communicate our pod inside and outside of the cluster
     -> pod  -> Pod is a small execution unit. Pod having group of containers it will run single container and multiple containers.

# What are the Kubernetes workload types
-> Pod
-> Replica Controller
-> Replica Set
-> Deployment
-> Stateful Set
-> Daemon Set
-> Job
-> Cronjob



# What is Pod
-> Pod is a small execution unit. Pod having group of containers it will run single container and multiple containers.
-> we can create pod in two way
   -> Interactive 
   -> Declarative
-> In Interactive we will create pod using CLI Commands
   -> kubectl run --name <container name> --image=ashokit/javawebapplication
-> In Declarative will create pod using menifeast files

-> Pod is ephemeral [It lives short period time]
-> If pod will delete any reason it won't create another pod
-> For that, we should use Replica controller and Replica Set to get High availablity [It keep running]

# What is Replica Controller [Self healing capacity]
-> We can scale up and scale down our pods
-> We can create Multiple pods

# What is Replica Set
-> It is the Advance feature of replica controller
-> We can scale up and scale down our pods
-> We can create Multiple pods

# What is the difference between Replica Controller and Replica Set
-> Replica Controller will support the single selector
-> Replica Set will support the multiple selectors

-> kubectl scale <resource type> <deployment name> --replicas=<number of replicas>

-> If we want rollout and rollback our pod and autoscaling we need deployment

# What is Deployment
-> By using Deployment we can rollout and rollback our application. We can achive even autoscaling

-> In Deployment we have so many strategies 
   -> Recreate Deployment
   -> Rolling Update Deployment
   -> Blue and Green Deployment [It's a approach not a Deployment starategy]
   -> Canary Deployment

# What is Recreate Deployment
-> First it will stop all old pods then it will create new pods
-> It's a simple deployment but it's leads to downtime because no pods available during traffic switching

# What is Rolling Update Deployment
-> It will terminate the old pods one by one while it will create the new pods one by one
-> It is default kubernetes deployment. we can easily the rollback the old image version. 
-> It will deploy with zero downtime but mixing old version and new vesion images. it would be risk if version not work.

# What is Blue and Green Deployment
-> We have two environments one is blue (current env) and green(new env)
-> We can easily switch traffic from blue to green once green ready
-> we should maintain two infrastructure env it lead to the high cost

# What is Canary Deployment
-> Release the new version to small subset of users, if it is not occur any error then we will release to everyone
-> We can easily detect the problems and safely test in production
-> Monitoring is needed


# What is StatefulSet
-> StatefulSet is a kubernetes workload API object is used to manage stateful applications, that application requires
    -> Stable Storage
    -> Unique Network
    -> Ordered deployment, scaling and deletion

# What is the difference between Deploymet and StatefulSet

| Feature          | Deployment                 | StatefulSet                            |
| ---------------- | -------------------------- | -------------------------------------- |
| Pod Name         | Random (`pod-xyz-abc`)     | Stable and predictable (`pod-name-0`)  |
| Storage          | Shared or Ephemeral(EFS)   | Stable and Persistent (via PVCs) (EBS) |
| Pod Identity     | Not guaranteed             | Stable network identity (`pod-name-0`) |
| Start/Stop Order | Not guaranteed             | Ordered start/stop                     |
| Use Case         | Stateless apps (e.g., web) | Stateful apps (e.g., databases)        |


# What Daemon Set
-> Daemon Set Ensures one or more copy of pods running every workernode in cluster
-> It is mostly used for log collectors, Node Monitoring agent and security agaent

# What is the difference between Deployment and Daemon Set
-> In Deployment we deploy the pod based on replica it will run the pods in differnet nodes or even multiple pods in one node
-> In Daemonset When we use Daemonset it will ensure the pod running every workernode in cluster. If you add any new workernode it will also automatically create the pod in that workernode.


# What is Job
-> It will run pod until task complete then it stops
-> It is used for onetime task
-> It will mostly used data migration and send mail at one time

# What is Cronjob
-> It will run the job on schedule like simalar linux cron jobs
-> It is mostly used for taking database backups, sending monthly reports


# What is Autoscaling
-> We have two types of Autoscaling 
    -> Horizontal Pod Autoscaling [HPA]
    -> Vertical Pod Autoscaling [VPA]

# What is Horizontal Pod Autoscaling
-> It will increase the pods based on CPU and Menory Utilization when the load increase on pods

# What is Vertical Pod Autoscaling
-> It will increase the capacity of system means it will increase the CPU and Memory Size when the load increase on pod but it needs to do restart it will leads to down time. That's why it's not recommended



# What is services
-> If we want to access our pod inside and outside of the cluster after create pod we need service in kubernets
-> we have some services in kubernetes
   -> CLusterIP
   -> NodePort
   -> LoadBalancer
   -> ExternalName
   -> Headless

# What Cluster Ip
-> Cluster It will work to access our pod only inside our cluster

# What NodePort
-> NodePort It will work to access our pod inside and outside of cluster with node Ip and static port of each node

# What LoadBalancer
-> LoadBalancer it will work to access our pod inside and outside of cluster with automatically provisined load balancer URL

# ExternalName
-> ExternalName service allow kubernetes service act as a ailas to external DNS Host
-> It's returns the CNAME Record to external DNS Host

# Headless
-> Headless service is needed so each pod get specific stable DNS name
-> It is mostly use in statefulset application where client can directly connect to specific pod


# What is Namespace
-> In Kubernetes namespace is virtul cluster in kubernetes
-> Namespaces are primarily user for creating the isolated environment and prevent resource conflicts between different applications or users.
-> We will create some namespace defaultly after setup cluster
    -> default
    -> kube-system   --> It container Kubernetes control plane componenets
    -> Kube-public  -> It is reserved for k8S system usage



# What is Compute Resources
-> CPU and Memory we called Compute Resources
-> CPU measure in Vcores
-> Memory Measure in Bytes
-> We have two options under Compute resource
   -> request
   -> limit

# What is request
-> This defines the minimum amount CPU and Memory container is needed. Kubernetes is use to decide where to schedule the pods, if the node are not enough available resource then it won't schedule the pod.

# What is Limit
-> This defines the maximum amount CPU and Memory container is allowed to use. If container is tried to use more than limit then CPU throttled and memory killed


# What is ConfigMap
-> ConfigMap are used to store the config data consumed by pod and another resources
-> It will store the non-sensitive data like username.

# What is Secret
-> Secret are used to store the sensitive data like password and tokens.

# What are the Types of secrets
-> Obaque:- It is most commonly used secret. It allow us to store key value pairs
-> Docker-Registry:- It will store the credentials to authendicate the private Docker registry
-> TLS:- It will store the Certificates
-> Service-Account:- It will automatically create the secrets that provide credentials for accessing the kubernetes API


# What is Ingress
-> Ingress is a API Object that provides external access to the service within the cluster
-> It route the traffic from outside the cluster to internal services based on rules

# Why Do We Use Ingress?
-> With Ingress we can expose the mulitple services over single IP/Host with different path and subdomains
-> Without Ingress we can expose the service with load balancer and node port which is heavy cost and not scalable

# What is Ingress Controller
-> The Pod running the inside the cluster that reads the ingress rules and configure the reverse proxy to handle the traffic

# What is ingress resource
-> Define routing rules

# Types of path based routing and Host based routing
# Path base routing
-> We need to single domain
-> Single DNS record enough

# Host base routing
-> We need to mulitple domain and subdomain
-> Need DNS record for each host



# What is Network Policy
-> Network Policy in Kubernetes is security rule that controls how pods to communicate to each other and with external endpoint over the internet
-> It act as firewall for pods, It defines which pod can talk to which, on which port and using which protocal.

# Why we need Network policy
-> By default in kubernetes, All pods can communicate each other, By using network policy we can restrict the pod communication based on
     -> lables
     -> Namespaces
     -> IP address
     -> Protocals and ports


# What is RBAC
-> RBAC stands for role base access control 
-> It defines the different level of permission and access level to different users based on rules
-> RBAC is the heart of Kubernetes security
-> We have two types of roles
   -> Role [It will work on specific namespace]
   -> Cluster Role [It will work on cluster level. It works on all the namespaces]


# What is volumes in Kubernetes
-> Volumes in Kubernetes are tied with pods not with container, that's why even if container crash or restart we won't loss our data as long as pod alive

# What are the types of volumes
-> Emptydir
-> Hostpath
-> Persistence volumes
-> Config/secret
-> NFS

# What is Emptydir
-> It store the data Temporary share between container in pod
-> We will loss our data if pod crash or kill
-> It wont support to share data across mulitple pods on different nodes

# What is Hostpath
-> It mount the files and folder from host node to pod
-> It store data as long as pod schedule in same node. If its schedule in another node, will lose our data
-> It wont support to share data across mulitple pods on different nodes

Note: The above two are ephemeral it's not recommend

# What is persistence volume
-> It will store the data as a persistence backend like [EBS, EFS]
-> We can retrive the data even if pod crash or kill
-> It will support the share the data across multiple pods on different node
-> we have three components in persistence volume
    -> Persistence Volume
    -> Persistence Volume Claim
    -> Storage Class

# What is Persistence Volume
-> Persistence Volume is a Piece of storage in kubernetes that has beed provisioned by an administrator and dynamically provisioned storage class

# What is Persistence Volume Claim
-> Persistence Volume Claim is the request for storage By administrator or user
-> Kubernetes will support some access modes in persistence volume claim
    -> RWO [Read Write Once]
    -> RWX [Read Write Many]
    -> ROX [Read Only Many]
    -> RWO-Pod [Read Write Once Pod]

# What RWO
-> It will mount the volume by Single Node
-> It is best for pod is running in same node
-> EBS will support

# What RWX
-> It will mount the volume by mulitple Nodes
-> It is best for share the data accross multiple pods on different nodes

# What ROX
-> It will mount volume as read only by multiple nodes
-> It is best for static data

# What RWO-Pod
-> It will mount the volume as read write Once pod by single pod, even if multiple pods are running on node
-> Useful for strong isolation — only one pod in the entire cluster can read/write.

# What is Storage Class
-> Define How Dynamically provisioned persistence volume
-> Automatically create PV when PVC are request


# What is Liveness probe and readness probe in kubernetes
🔹 1. Liveness Probe
Purpose: Checks if the container is still running (alive).
If the liveness probe fails → Kubernetes kills the container and restarts it.

🔹 2. Readiness Probe
Purpose: Checks if the container is ready to accept requests.
If the readiness probe fails → Kubernetes removes the Pod’s IP from the Service’s endpoints.


# How does two conatier can communicate in single node
-> In Kubernetes, when two containers run in the same Pod (on the same node), they communicate with each other using localhost (127.0.0.1)` because they share the same network namespace.

# How does two pods can communicate in single node
-> It can communicate with each other via their Pod IPs

🔹 1. Each Pod gets its own IP
Kubernetes uses a CNI plugin (Container Network Interface) like Flannel, Calico, Weave, etc.
Every Pod gets a unique IP address in the cluster network, even if they are on the same node.

# How Pods on Different Nodes Communicate
When Pods are on different worker nodes, they still need to talk to each other with the help of Container Network Interface (CNI) plugin.


# What is CNI?
-> CNI = Container Network Interface
-> It’s a standard (defined by CNCF) for configuring network interfaces in Linux containers.
-> Kubernetes doesn’t implement networking itself — instead, it relies on CNI plugins to provide Pod networking.

# What does a CNI plugin do?
When a Pod is created:
-> Assigns an IP address to the Pod (so every Pod has its own IP).
-> Sets up networking rules so Pods can send/receive traffic.
-> Handles cross-node communication (routing/encapsulation).
-> Manages Pod-to-Service communication when combined with kube-proxy.


# What is the difference between Docker container and kubernetes pod?
🐳 Docker Container
-> Docker Container Runs a single application/process (e.g., Nginx, MySQL, Node.js service).
-> Focused only on containerizing applications.

☸️ Kubernetes Pod
A Pod Runs one or more containers.
Pods are managed by higher-level objects like Deployments, StatefulSets, DaemonSets.
Focused on orchestration, scaling, and self-healing of containers.

# How do you handle the Kubernetes cluster Security
Kubernetes security is about defense in depth:
-> Secure cluster access (RBAC, API server).
-> Secure workloads (Pod Security, least privilege).
-> Secure networking (NetworkPolicies, mTLS).
-> Secure data (Secrets encryption).
-> Continuous monitoring (logging, scanning, auditing).


# What is Service Mesh [If anyone ask i know how it will work but i don't work on particully 
-> Service mesh is used for to communicate from one service to another service securaly
-> Servie mesh is used for running east-west tarffic in cluster
-> Enabling the mutual TLS
-> Service mesh provides the some capabilities such as load balance, observability, tarcing, authentication and 
   authorization etc

# What is init container and why do we need it
🚀 What is an Init Container in Kubernetes?
-> An Init Container is a special type of container in a Kubernetes Pod that runs before the main application containers start.
-> It always runs to completion (successfully exits) before the main container(s) are started.
-> You can have one or multiple init containers in a pod.
-> If an init container fails, Kubernetes will restart it until it succeeds (or the pod is deleted).

⚙️ Why Do We Need Init Containers?
They are useful for tasks that need to be done once, before the main app runs:
Dependency Initialization
Wait for another service (like a database) to be ready.
Example: Ensure MySQL is up before starting the backend.


# What Pod Disruption Budget  (Prevents too many pods from going down)
-> A PodDisruptionBudget (PDB) in Kubernetes is a resource that ensures high availability of your application during voluntary disruptions like:
     Node drains (e.g., during upgrades)
     Cluster maintenance
     Rolling updates


# How do you scale your application dynamically based on the number of incoming requests in Kubernetes?
-> By using Horizontal Pod Autoscalling


# If you have 2 containers in the same pod and one container's liveness probe fails, what happens?
-> In Kubernetes:
	Each container in a Pod can have its own liveness probe.
	If the liveness probe of Container A fails:
	Kubernetes restarts only Container A.
	Container B (in the same Pod) continues running unaffected.

	🔁 What does "restarted" mean?
	It does not recreate the Pod.
	It simply kills and restarts the failing container inside the same Pod, retaining:
	The same IP address
	The same volume mounts
	The same networking setup


# How do you configure log file sharing when one container writes logs and another container accesses them in the same pod?

✅ Use Case
One container (e.g., app-container) writes logs to a file.
Another container (e.g., log-agent) reads or ships those logs (like a sidecar).

✅ Solution: Use emptyDir Volume
emptyDir creates a temporary directory shared across containers in the same Pod.


# How do you confirm if the second container has access to the logs generated by the first container?
✅ 1. Use kubectl exec into the second container
Run this command to open a shell inside the second container (e.g., log-reader):

kubectl exec -it log-sharing-pod -c log-reader -- sh
✅ 2. List the shared log directory
Inside the second container's shell:
ls -l /var/log/app
You should see the log file (app.log) written by the first container.

✅ 3. Tail or read the log file
To confirm contents:
cat /var/log/app/app.log
or
tail -f /var/log/app/app.log
If logs are streaming, you’ll see the entries generated by the first container.



# How do you configure permissions to delete pods in k3s using RBAC?
To configure permissions to delete pods in k3s using RBAC (Role-Based Access Control), you need to:
Create a Role (or ClusterRole) that allows delete on pods.
Bind it to a ServiceAccount and role using RoleBinding (or ClusterRoleBinding).


# How do you write a script to delete completed pods in Kubernetes?
-> kubectl delete pod --all-namespaces \
  --field-selector=status.phase==Succeeded,status.phase==Failed

# How do you delete all pods in all states in a namespace or cluster-wide?
-> kubectl delete pods --all -n <namespace>


# What are StorageClasses in Kubernetes?
-> A StorageClass in Kubernetes defines how storage is provisioned dynamically for PersistentVolume(PV).

# A pod is CrashLoopBackOff. How do you troubleshoot?
-> I do run the kubectl describe pod <pod-name> -n <namespace> to idenitfy the error, mostly we get this CrashLoopBackOff due to 
   Non-zero exit code
   Image pulling issues
   Probe failures
   Volume mount or permission errors


# Your deployment is not scaling. What might be the reasons?
-> Resource limits on the nodes
-> Insufficient CPU/memory
-> Misconfigured HPA


# Network connectivity between pods is failing. How do you debug?
-> Check CNI plugin status
-> Ensure all pods are in same network space
-> Try to Ping or Curl Between Pods
   -> kubectl exec -it <source-pod> -n <namespace> -- ping <destination-pod-IP>
   -> kubectl exec -it <source-pod> -n <namespace> -- curl http://<destination-pod-IP>:<port>

#  Application is slow in Kubernetes. What areas do you check?
-> Pod resource limits and usage
-> Node health (kubectl get nodes)
-> Network latency (Istio, Cilium metrics)
-> Persistent storage I/O
-> Liveness/Readiness probes delaying traffic


# How would you implement blue-green deployment in Kubernetes?
Answer: Deploy both versions (blue and green) and use Services or Ingress to switch traffic. Can also use labels and selectors dynamically.

# How do you upgrade a Kubernetes cluster?
-> Monitor the logs and health post-upgrade
-> Use kubeadm upgrade plan (if using kubeadm)
-> Upgrade control plane first
-> Upgrade worker nodes one-by-one

# ETCD is unhealthy, and API server is timing out. Steps to recover?
-> Check etcd logs
-> Verify disk/storage health
-> Restore from etcd backup (etcdctl snapshot restore)
-> Restart control plane components

# You see high CPU usage in kubelet. What could be wrong?
-> Too many pods on a node
-> Frequent log rotation
-> Heavy resource metrics scraping (Prometheus)
-> Check logs, garbage collection, and kubelet flags
