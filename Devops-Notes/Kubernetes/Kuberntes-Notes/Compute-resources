# What is compute resource
-> CPU and memory we called compute resources

# What is CPU and Memory
# CPU
-> Measured a fraction of time
-> Ex=200m(0.2cpu), 1cpu(1000m)
-> Compressible
-> Throttles means it wont kill even through we cross the CPU limit because it is Compressible
-> 1 CPU is equal to
      1 vCPU in AWS
      1 core in GCP
      1 vcore in azure
      1 Hyperthread on bare-metal

# Memory
-> Measured on bytes
-> Ex=1KB (1000 bytes), 1KiB (1024 bytes)
-> Ex=1MB (1000 kb), 1MiB (1024 kib)
-> Not compressible
-> Terminates

"We have two options under resources in Kubernetes:
requests â€“ This defines the minimum amount of CPU and memory the container needs. Kubernetes uses this to decide where to schedule the pod. If a node doesnâ€™t have enough available resources as per the requests, the pod wonâ€™t be scheduled on that node.
limits â€“ This defines the maximum amount of CPU and memory the container is allowed to use. If the container tries to use more than this limit:
For CPU, it gets throttled.
For memory, it can be killed (OOMKilled)."

âœ… In Short:
Requests = Minimum guaranteed. Used for scheduling.
Limits = Maximum allowed. Enforced during execution.
â†’ You can use more than requests only if the node has spare resources and you're within your limits.

# Example
You're running a Node.js application in a pod with the following resource configuration:

resources:
  requests:
    cpu: "200m"
    memory: "128Mi"
  limits:
    cpu: "500m"
    memory: "256Mi"

This means:
The pod requires:
200 millicores (0.2 CPU cores)
128 Mi of RAM

The pod is allowed to use up to:
500 millicores (0.5 CPU cores)
256 Mi of RAM

ðŸ’¡ Real-Time Behavior:
âž¤ Step 1: Pod Scheduling
Kubernetes checks which node has at least 200m CPU + 128Mi RAM free.
It schedules the pod on that node.
The pod is created and starts running.

âž¤ Step 2: Pod is Idle (Uses 50m CPU + 60Mi RAM)
Everything is fine â€” itâ€™s using less than the request.
It has guaranteed access to 200m CPU and 128Mi RAM even if the node gets crowded.

âž¤ Step 3: Traffic Increases (Uses 400m CPU + 200Mi RAM)
Pod is now using more than it requested, but still under the limit.
It works fine â€” no throttling or killing.
This is possible because the node has enough free resources at runtime.

âž¤ Step 4: Pod Exceeds Limit (Uses 600m CPU or 300Mi RAM)
Kubernetes enforces limits:
CPU: Container is throttled â€” it slows down.
Memory: Container is killed (OOMKilled) â€” pod may restart.

ðŸ“Œ Observing It in Action
You can try this yourself using a test pod and the stress tool:

1. Create a test pod:
kubectl run stress-pod --image=alpine --restart=Never -it -- \
  sh -c "apk add --no-cache stress && stress --cpu 2 --vm 1 --vm-bytes 300M --timeout 30s"

2. Apply a resource limit (or in a deployment YAML):
resources:
  requests:
    memory: "100Mi"
    cpu: "100m"
  limits:
    memory: "200Mi"
    cpu: "300m"

3. Check what happens:
It will likely be OOMKilled, because it's asking for 300M RAM but limit is only 200Mi.

4. Watch with:
kubectl get pods
kubectl describe pod stress-pod




CPU measures in cores
  250m -> 250 milliCPus  -> 0.25 core

Memory measures bytes
  250mi -> 250 mebibytes

resources:
  requests:
      cpu: "100m"
      memory: "64Mi"
  limits:
      cpu: "100m"
      memory: "256Mi"


# How to install metrics
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl get pods -n kube-system
kubectl top nodes   --> To see the node capacity
kubectl top pods -n default  --> To see the pods capaticy

# To set the limit

apiVersion: v1
kind: LimitRange
metadata:
  name: limit-range
spec:
  limits:
    - type: Pod
      min:
        cpu: 50m
        memory: 5Mi
      max:
        cpu: "2"
        memory: 6Gi
    - type: Container
      defaultRequest:
        cpu: 100m
        memory: 10Mi
      default:
        cpu: 200m
        memory: 100Mi
      min:
        cpu: 50m
        memory: 5Mi
      max:
        cpu: "1"
        memory: 5Gi
      maxLimitRequestRatio:
        cpu: "4"
        memory: 10
    - type: PersistentVolumeClaim
      min:
        storage: 1Gi
      max:
        storage: 10Gi


kubectl get limitrange -n default
kubectl delete limitrange <name of limit> -n default
kubectl describe limitrange <limitrange-name> -n <namespace>

# To set the quota

apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota
spec:
  hard:
    requests.cpu: 400m
    requests.memory: 200Mi
    limits.cpu: 2000m
    limits.memory: 8Gi
    pods: "10"
    replicationcontrollers: "5"
    secrets: "10"
    configmaps: "10"
    persistentvolumeclaims: "4"
    services: "5"
    services.loadbalancers: "1"
    services.nodeports: "2"
    # Only two PVCs can claim storage with the ssd StorageClass.
    ssd.storageclass.storage.k8s.io/persistentvolumeclaims: "2"


kubectl get resourcequota -n default
kubectl delete resourcequota resource-quota -n default
kubectl describe limitrange <quotaname-name> -n <namespace>

# If you want to work on limits and quota
-> limit range means it validates the each pod in namespcae sometime if you want to restrict at namespace level then we should use quota
https://github.com/pelthepu/Kubernetes/tree/master/resources/resource-management   --> To get limit and quota yaml files
https://youtu.be/MbgFIQoVh6w?si=Q_MRCWRSDMsh2qxi  --> To get more idea you will watch this video link
