# What is kubernetes
-> Kubernetes is a powerful open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications.
-> k8s is not replacemt of docker
-> k8s is replacement of docker-swarm
-> k8s is developed by google and donted CNCF in 2014 
    [CNCF means cloud native computing foundation]
-> k8s software developed by using Go langauge
-> k8s version relased to market in the year of 2015
-> K8s script write in json format
-> k8s works on clouste mudules

# Why we are using K8S
-> Kubernetes is a powerful open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications.
-> To achive the below features we will use k8s
  -> Auto Scheduling
  -> Self healing capacity
  -> Rollout and Rollback
  -> Auto scalling
  -> Service discovery
  -> Storage orchestration
  -> Secret and configuration management

# What is Docker-swaram
-> Docker Swarm is a container orchestration tool for clustering and scheduling Docker containers.

# What is the difference between Docker-swaram and kubernets
# Docker swarm
-> Easy to start the cluster
-> Manual Autoscaling
-> Need third party tool to monitor like ELK
-> Auto setup of load balancer
-> No expernice with production deployment 
-> Docker swarm is better suited for small organisation

# Kubernetes
-> Difficult to start the cluster
-> Automatic autoscaling
-> Intergrated tool
-> Manual setup of load balancer
-> expernice with production deployment 
-> Kubernetes is better suited for large organisation

Note:- Docker-swaram it will install all the components like API, ETCD .. in os.
       Kubernetes it will install all the components as a container
       If any component goes down in docker swaram entire master will halted. In Kubernetes if it goes it will create new container along with all the components.

# What are the features of K8S
-> Auto Scheduling
-> Self healing capacity  [Replication controller]
-> Rollout and Rollback  [Deployment]
-> Auto scalling
-> Service discovery
-> Storage orchestration
-> Secret and configuration management

# What is Auto Scheduling
-> Kubernets will provide the advance schedular option to launch the containers based on your reruirment

# What is Self healing capacity
-> If a containerized app or an application component fails or goes down. Kuberneted re-deploy it to retain the desired state

# Rollout and Rollback
-> If something goes wrong, kubernets will rollback the change for you

# Auto scalling
-> Autoscaling allow you to automatically scale up and scale down your application based on cpu utilization and memory utilization
    Note: Docker-swarm load balancing is manual process
          kubernets supports autoscaling load balancer
# Service Discovery
-> Kubernets will take care the every thing about network.

# Storage orchestration
-> Kubernets will automatically mount the storage

# Secret and configuration management
-> Depoly and update secrets are not exposing in your stack configuration

# Kubernets Architecture
-> k8s works on cluster modules
-> In k8s cluster we will have masternode and workernode
   -> Master Node  [Master node will manage the worker node in cluster]
   -> Worker node  [Worker will run the tasks assign by master node]

# To Communicate with kubernets cluster we have 2 options
-> UI (user interface)
-> Kubectl (CLI S/w)

# What is Kubectl
-> Kubectl is command line interface(CLI) for interacting with Kubernetes clusters
-> Kubectl is used to run the commands on kubernetes cluster

# What are the components in master node
-> API
-> ETCD
-> Scheduler
-> Control manager

# What is API 
-> API server will act as communicator between develop/Devops and K8s componets

# What is ETCD
-> It act as database in k8s
-> ETCD will stores cluster information such it current state, desitred state, configuration resources and runtime data.
-> Whenever we run k8s application that request goes to the API Server and API server will store the request in ETCD.

# What Schedular
-> It will scheduled the pods for execution which are unschedule in ETCD
-> Schedular will schedule the pods to workernode with the help of Kubelet

# What is Control manager
-> The Controller Manager monitors the current state of your cluster through the API Server and makes appropriate changes to keep the application running by ensuring sufficient Pods are in a healthy state.

# What are the components in worker node
-> kubelet
-> container runtime [docker]
-> kubeproxy [Network proxy]
-> Pods

# What is kubelet
-> Kubelet will act as a node-agent 
-> kubelet ensure the containers are running healthy in pod 
-> kubelt will interact with container runntime to create the container

# What is container runtime
-> It is responsible for managing the execution and lifecycle of containers within the Kubernetes environment.

# What is kube-proxy
-> kube proxy act as network proxy
-> Kube proxy will maintain network rules on pods
-> The network rules allow the network to communicate your pods from inside and outside of the cluster

# What is Pod
-> Pod is small execution unit in K8s
-> Pod having group of containers
-> Containers will grouped as a pod in order to increase the intelligence of resources
-> Pod will run single container and multi container.


# How types of pods can you create
-> We can create two types
-> Interactive apporoach
       In interactive approach we can create pod using command
        kubectl run --name conatinername --images=ashokit/javawebapplication
-> Declarative apporoach
      Declarative Approach means we will create the pod using manifest file(yml)
	apiVersion -> It represents the version
	kind -> What is the purpose of the manifeast file 
	metadata -> It represents the lables
	spec -> What do you want to use this manifeast file
	filename default is .yml

# How many service in Kubernetes
-> Cluster IP 
-> Nodeport
-> Load Balancer
-> ExternalName Service
-> Headless Service

# What is Cluster IP
-> If we use Cluster Ip Services we can access the pod inside of the cluster
    curl serviceip:portnumber

# What is Nodeport
-> If we use Nodeport service we can access the pod inside and outside of the cluster by using node Ip address
   [Port number range in K8S is 30000 to 32767]

# What is load balancer
-> If we use Load balancer service we can access the pod inside and outside of the cluster by using load balancer URL

# What is the difference between NodePort and Load Balancer
NodePort exposes a service on a static port on each node's IP, allowing external access to the service, while LoadBalancer automatically provisions an external load balancer to distribute traffic across multiple nodes or pods, providing a more robust and scalable solution for external access.

# What is ExternalName Service
-> ExternalName service allows kubernetes service act as a ailas to external DNS host
-> it returns a CNAME record pointing to the external host.

# What is Headless Service
->  Headless service (clusterIP: None) is needed so each pod gets a stable DNS name, 
    e.g., mongo-0.mongo.default.svc.cluster.local
-> It is mostly used for stateful application, where the clients need to connect directly to specific pods.

# What are the difference between pod manifest file and service manifest file
-> Pod manifest file having lables
-> service manifest file having selectors

# What is Replication Controller [Self Healing capabilities]
-> It is one of key feature in k8s
-> We can scale up and scale down the pods using replication controller
-> We can create the mulitple pods
-> We can achive high availablity using replication controller
   Note:High avaliablity means always our application should be accessable
-> kubectl scale deployment my-deployment --replicas=3

# What is Replication Set
-> It is next generation of Replication controller
-> We can scale up and scale down the pods using replication controller
-> We can create the mulitple pods
-> We can achive high availablity using replication controller
   Note:High avaliablity means always our application should be accessable

# What is the difference between Replication Controller and Replication set
-> Selectors is the difference between Replication Controller and Replication set
-> We have two types of selector 
   -> Equality selector
   -> Set based selector
# What is Equality Selector
-> Equality Selecotr give the single selector
-> Replication controller supports Equality selector

# What is Set-based selector
-> Set-based Selecotr give the mulitple selector
-> Replication set supports Equality selector


# What is deployment
-> By using deployment we can rollout and rollback our application deployment
-> we can achive the auto-scalling by deployment

# How many types of deployment strategies
-> Recreate deployment strategy
-> Rolling deployment strategy
-> Blue and green apporach [It is not a strategy it is a approach]
-> Canary Deployment

1. Recreate Strategy
Process: Stops all old pods first, then starts all new pods.
Pros: Simple to implement, ensures a clean slate.
Cons: Causes downtime because no pods are available during the switch.

2. Rolling Deployment Strategy  (Default in Kubernetes.)
Process: Replaces pods gradually — old pods are terminated one by one while new ones are added.
Pros: No downtime, safer than recreate. Easy rollback by restarting old image version.
Cons: Temporary mix of old and new versions. Risk of incompatibility if versions can’t work together.

3. Blue-Green Approach (an approach, not a built-in strategy)
Process: Keep two complete environments — Blue (current) and Green (new).
Traffic is switched from Blue to Green once Green is ready.
Pros: Instant rollback by switching traffic back.
Cons: Requires double infrastructure temporarily, higher resource cost.

4. Canary Deployment
Process: Release new pods to a small percentage of traffic first, then gradually increase if no issues occur.
        Release the new version to a small subset of users before rolling it out to everyone. 
Pros: Early detection of problems. Allows safe testing in production with real traffic.
Cons: More complex routing and monitoring needed.

| Strategy/Approach | Downtime | Resource Usage During Deploy | Traffic Mix   | Rollback Complexity |
| ----------------- | -------- | ---------------------------- | ------------- | ------------------- |
| **Recreate**      | High     | Low                          | No            | Medium              |
| **RollingUpdate** | None\*   | Slightly higher              | Yes           | Low                 |
| **Blue-Green**    | None     | High                         | No            | Very Low            |
| **Canary**        | None     | Medium                       | Yes (small %) | Low–Medium          |



# What is Namespace
-> In Kubernetes, a namespace is a virtual cluster within a Kubernetes cluster. 
-> It is used to organize and scope resources within the cluster, providing a way to divide cluster resources between multiple users, teams, or projects. 
-> Namespaces are primarily used to create isolated environments and prevent resource conflicts between different applications or users.
-> kubernets components will be grouped logically using namespaces
Note: we can consider namespace as a java package
-> we will get 3 namespaces when we setup the kubernets cluster
1) default -> It doesnt specify any namespace
2) Kube-system -> It contains K8S Control panal Components
3) Kube-public  -> It is reserved for k8S system usage


# What is Autoscaling
> Auto Scalling allow to you to automatically scale up and scale down your application based CPU Utilization and Memory Utilization
-> We have two types of auto scalling
  1) Horizontial scalling
  2) Vertical scalling

-> Horizontial Scalling increase the number of instances based CPU Utilization and Memory Utilization when increase the load on servers
-> Vertical Scalling increase the capacity of system means increase the CPU and Memory size when increase the load on servers but it need to do restart it will affect somedown time it is stateless nature


# What is Helm
-> Helm is a package manager for K8S application
-> Helm allows you to install or deploy application on K8S cluster in a smillar mannaer to yum/apt for linux system

# What is Prometheus [ It is a monitoring tool]
-> Prometheus is an open-source system monitoring and alerting toolkit.
-> Prometheus collect and store its metrics as time series data
-> Prometheus out-of-the box monitoring capabilities for the K8S container orchestration platform
 
Note:Prometheus will collect the data and Prometheus will give the data to grafana and grafana analysis the data and
   generate the charts and graphs for users

# What is Grafana [It is a visulation tool]
-> Grafana is database analysis and monitoring tool
-> Grafana is multiplatform open source analytics and interactive visualiization web application
-> Grafana will connect with prometheus with data source 

# What is ELK Stack [To monitor the application logs]
-> The ELK stack is a collection of three open-source
   E: Elastic Search -> For store the logs
   L: Log stash -> Enchances the data and sent to the Elastic search
   K: Kibana -> It display the data stored in elastic search [Kibana is a monitoring tool for logs]
-> It allows you search the all logs in single place

# What is config
-> Config is used to store the config data conusmed by pods and other resourece in cluster

# What is Secret
-> Secret is used to store the senities data like username and password

# What are the types of secrets
-> Opaque -> the most common type of secret. It allows you store the keyvalue pairs
-> Docker-Registry -> used fot storing credientionls to authenciate with private Docker Registry
-> TLS -> It is used to store the TLS certification
-> Service Account -> Automatically created the secrets that provide the credientials for accessing kubernetes API

# What is compute resource
-> CPU and memory we called compute resources

# What is CPU and Memory
# CPU
-> Measured a fraction of time
-> Ex=200m(0.2cpu), 1cpu(1000m)
-> Compressible
-> Throttles means it wont kill even through we cross the CPU limit because it is Compressible
-> 1 CPU is equal to
      1 vCPU in AWS
      1 core in GCP
      1 vcore in azure
      1 Hyperthread on bare-metal

# Memory
-> Measured on bytes
-> Ex=1KB (1000 bytes), 1KiB (1024 bytes)
-> Ex=1MB (1000 kb), 1MiB (1024 kib)
-> Not compressible
-> Terminates


-> We have two options in resources 
  1. requersts  [it will schedule the pods in nodes based on how much CPU and memory you have mentioned in requersts if node does not have that CPU and memory it wont schedule the pods]
  2. limits    [Your container can use only that amount of CPU and memory which you mention in limits]

# What is CRD
-> CRD Stands for Custom resource Definition
-> CRDs allow users to create new types of resources without adding another API server.
-> When you create a new CustomResourceDefinition (CRD), the Kubernetes API Server creates a new RESTful resource path for each version you specify. 


# What is Daemon Set
-> Daemon set in kubernets lets you run pods in all the nodes
-> We will create the daemon set for log collections, monitoring and storage

# What is the difference betwenn regular deploymnent and Daemonset
-> Deployment means:- When we deploy the pod in kubernets pods will run the in nodes based on replica. If new node create in cluster pod wont add in that node.
-> DaemonSet means:- When we deploy the pod in kubernets pods will run in all the nodes. If new node create in cluster pod will add automatically in that new node.


# What is ingress
-> Ingress is an API object that provides external access to service within cluster.
-> It route the traffic from outside of cluster to internal service based on path and host

-> Path base routing  --> we use single domain name to server the multiple apps
-> Host base routing  --> we use different sub-domain names to server the multiple apps

# what is the difference between job and cronjob in kubernetes
While Jobs are designed for running one-time or on-demand tasks, CronJobs are used for executing tasks at regular intervals


# What is network policy in k8s
-> Network policy in kubeentes is the security rule that controls how the pods can communicate with each other
-> It works as firewall of pod define the which pod to take to which on which port and usgin which protocal (TCP/UDP)

📦 Why Use NetworkPolicy?
By default in Kubernetes:
All pods can talk to each other (no restrictions).

With NetworkPolicy:
You can restrict traffic between pods based on:
Pod labels
Namespaces
IP blocks
Ports and protocols

-> Ingress  --> It control the internal traffic to selected pods
-> Egress   --> It control the external traffic from selected pods



# What is RBAC
-> RBAC is the way to define the different level of permission or access level for different users based on rules
-> RBAC is the heart of kubernetes security
-> RBAC is a key security control to ensure that cluster users and workloads have only the access to resources required to 
   execute their roles.
-> We have two types of roles
  1. ROle:- Role is work on specific namespace
  2. Cluster Role:- Cluster role is work on cluster level means it work on all the namespaces



# What is volumes in Kubernets
A volume's lifecycle is tied to the pod, not the individual containers. This means even if a container crashes and is restarted, the volume will still retain its data.

# Types of Volumes:
-> emptydir  --> emptyDir creates a temporary storage shared across containers in the same Pod.
-> Host      --> It mount the file and folder from host into pod
-> Persistance volume claim  --> Use persistance volume to request the storage from external system resource like EBS, EFS
-> NFS  --> Connect the NFS storage to share the data between pods
-> Config/Secret  --> Mount the config and secret as a file in container

What is emptydir
-> When we use emptydir we can store the data temporary across the container in pod
-> If pod will kill or crash we will deprived the data
-> It won't the support the persistence volume and share the data between across pods

What is Host
-> When use the Host we can mount the file and folder from host into pod
-> we can ratain the data even if pod delete and restaed because it will store in node
-> It won't the support the persistence volume and share the data between across pods

Above Two volume are epmerial it is only used for temporary purpose

What is persistence volume claim
-> The persistence volume claim is used to store the data in persistence block like EBS, EFS
-> we can abale to retain the data even if pod or node restarted and crash
-> It support to persist the data and share the data across the multiple pods 

We have components in persistence
-> persistence volume
-> persistence volume claim
-> Storage Class

What is persistence volume
-> A PersistentVolume is a piece of storage in the Kubernetes cluster, It has been provisined by administator or dynamically provisioned using stoage class

What is persistence volume claim
-> The persistence volume claim is the request for storage by user or developer

What is Storage class
-> A StorageClass in Kubernetes defines how storage is provisioned dynamically for PersistentVolume(PV).
-> Automatically creates PVs when PVCs are requested.

In Persistent Volume Claims (PVC), Kubernetes Supports These Access Modes:
ReadWriteOnce (RWO) 
-> It mount the volume as read, write by single node
-> Pod should always running in same node, we cant access if pod is running at different node
-> Most AWS EBS volumes use this access mode.

ReadWriteMany (RWX)
-> It mount the voume as read, write by mulitple node at sane time
-> We can share the data accross the mulitple pods on different node
-> Most AWS EFS, NFS volumes use this access mode.

ReadOnlyMany (ROM)
-> It mount the volume as read by multiple nodes at same time
-> We can use to server for static content (like config, images, etc.).

ReadWriteOncePod (RWO-Pod)
-> The volume can be mounted as read-write by a single pod only, even if there are multiple pods on the same node.
✅ Useful for strong isolation — only one pod in the entire cluster can read/write.

| **Concept**         | **Option**             | **What It Means**                                                                  |
| ------------------- | ---------------------- | ---------------------------------------------------------------------------------- |
| `volumeBindingMode` | `Immediate`            | PV is bound to PVC **immediately** after PVC creation                              |
|                     | `WaitForFirstConsumer` | PV is bound **only when a Pod is scheduled** using the PVC                         |
| `reclaimPolicy`     | `Delete`               | When PVC is deleted, the **PV and storage are also deleted**                       |
|                     | `Retain`               | When PVC is deleted, the **PV is retained** (you must manually delete or reuse it) |



# What is kubernetes Statefulset
-> StatefulSet in kubernetes is the workload API object used to manage stateful applications. That application is required
-> Stable, Unique name and network identities
-> Stable storage like persistence volume claim
-> Order deployment, scaling and deletion

# What is the difference between Deployment and Statefulset
| Feature          | Deployment                 | StatefulSet                            |
| ---------------- | -------------------------- | -------------------------------------- |
| Pod Name         | Random (`pod-xyz-abc`)     | Stable and predictable (`pod-name-0`)  |
| Storage          | Shared or Ephemeral        | Stable and Persistent (via PVCs)       |
| Pod Identity     | Not guaranteed             | Stable network identity (`pod-name-0`) |
| Start/Stop Order | Not guaranteed             | Ordered start/stop                     |
| Use Case         | Stateless apps (e.g., web) | Stateful apps (e.g., databases)        |


🧠 Key Features of StatefulSet
Stable name
-> We can create pod with predctable name

Persistence volume claim
-> Pod will get persistence volume claim, volume retaine even if pod restated or delete

Ordered Deployment & Scaling:
-> Pod will create, update and delete one at a time in a defined order.


# What is Calico network 
-> Calico is an open-source networking and network security solution for containers, virtual machines, and native host-based workloads.

In Kubernetes, Calico is commonly used as a CNI (Container Network Interface) plugin to provide:
-> Networking: Pod-to-pod communication (Assigns unique IPs to pods and handles their communication across nodes)
-> Network Policies: Fine-grained access control (who can talk to whom) (Implements Kubernetes NetworkPolicy for traffic control)
-> IP-in-IP or BGP based routing for performance and scalability



# How does two conatier can communicate in single node
In Kubernetes, when two containers run in the same Pod (on the same node), they communicate with each other using localhost (127.0.0.1)` because they share the same network namespace.

| Case                             | Can Use `localhost`? | How They Communicate        |
| -------------------------------- | -------------------- | --------------------------- |
| Containers in same **Pod**       | ✅ Yes                | `localhost:<port>`          |   curl http://localhost:8080
| Containers in different **Pods** | ❌ No                 | Pod IP or Service DNS       |  curl http://<pod-ip>:<port>
| Pods on same **Node**            | ❌ No                 | Still use Pod IP or Service |      # or
| Pods on different **Nodes**      | ❌ No                 | Via CNI, Pod IP or Service  |   curl http://<service-name>:<port>


To allow a pod on one node to communicate with a pod on another node, you don't need a special command—Kubernetes handles it automatically through the CNI plugin (like Calico, Flannel, Cilium, etc.).
But to test or manually check communication, you can use commands like:

✅ 1. Get Pod IP of the Target Pod
kubectl get pod <target-pod-name> -n <namespace> -o wide
🔹 This will show the IP address and which node the pod is on.

✅ 2. Exec into Source Pod and Curl Target Pod
kubectl exec -it <source-pod-name> -n <namespace> -- /bin/sh
Then inside the pod:
curl http://<target-pod-ip>:<port>


# How Does it happen to communicate two container inside the pod

| Shared Resource       | Behavior                                                                         |
| --------------------- | -------------------------------------------------------------------------------- |
| **Network Namespace** | Both containers share the **same IP address** and **localhost**                  |
| **Volumes**           | Can share files using shared **emptyDir** or mounted volumes                     |
| **Process Namespace** | (Not shared by default) Each has its own process tree unless configured to share |



# How Pod-to-Pod Communication within the Same Node
When two pods are scheduled on the same Kubernetes node, they can communicate with each other via their Pod IPs because each pod gets its own network namespace and unique IP address.

# How Pod-to-Pod Communication across Nodes
In Kubernetes, Pod-to-Pod communication across different nodes is fully supported and happens seamlessly via the Container Network Interface (CNI) plugin.

# How to describe the kubernetes security
-> Enable Role-Based-Access-Contro;
-> Use Third party authentication for API server
-> Protect ETCD with TLS and Firewall
-> Isolate the kubernetes nodes
-> Monitor network traffic to limit communications
-> Use process whitelsting
-> Turn on Audit logging
-> Keep kubernets version up and Date
-> Lock Down Kubelet
-> Secure kubernetes with Aqua


# Scenario based questions
# What is the difference between docker and kubernetes?

# What are the main components of kubernetes architecture?

# What is the difference between Docker swaram and kubernetes?

# What is the difference between Docker container and kubernetes pod?
a Docker container is an isolated environment for running a single application, while a Kubernetes pod is a higher-level abstraction that allows one or more containers to run together and be managed by Kubernetes.

# What is Namaspece in Kubernets

# What is the role of Kube-proxy

# What are the different types of services within kubernetes

# What is the difference between NodePort and Loadbalancer

# What is the role of kubelet

# How do you handle the Kubernetes cluster Security
-> RBAC
-> By default Pod can communicate with any another pods. we can set up the network policies to limit this communication 
   between pods
-> Use namespace for multi tenancy
-> Turn on audit logs


# What is Service Mesh [If anyone ask i know how it will work but i don't work on particully 
-> Service mesh is used for to communicate from one service to another service securaly
-> Servie mesh is used for running east-west tarffic in cluster
-> Enabling the mutual TLS
-> Service mesh provides the some capabilities such as load balance, observability, tarcing, authentication and 
   authorization etc

# What is init container and why do we need it
-> Init container are the container that should run and complete befor the startup the main container in the pod
-> It provides the separate lifecycle for the initialization so that it enables the separation of concens in the application

# What Pod Disruption Budget  (Prevents too many pods from going down)
A PodDisruptionBudget (PDB) in Kubernetes is a resource that ensures high availability of your application during voluntary disruptions like:

Node drains (e.g., during upgrades)
Cluster maintenance
Rolling updates

# Example
Let’s say your app is running on 4 pods in Kubernetes:

[ Pod-1 ]  [ Pod-2 ]  [ Pod-3 ]  [ Pod-4 ]

Now imagine:
Your cloud provider is upgrading a node (maintenance).
Kubernetes will evict (delete) the pods on that node.
If 2 or more pods go down at once, your app might crash or become slow.

😬 This is risky, right?

✅ What is the Solution?
You can tell Kubernetes:

“⚠️ Hey! Never allow more than 1 pod to go down. Keep at least 3 pods running at all times.”

This is exactly what PodDisruptionBudget (PDB) does


# What is Pod security policy in kubernetes
A **Pod Security Policy (PSP)** in Kubernetes is a cluster-level resource that defines security rules to control the behavior and configuration of pods, enforcing security best practices.


# How do you scale your application dynamically based on the number of incoming requests in Kubernetes?
-> By using Horizontal Pod Autoscalling

# If you have 2 containers in the same pod and one container's liveness probe fails, what happens?
-> In Kubernetes:
	Each container in a Pod can have its own liveness probe.
	If the liveness probe of Container A fails:
	Kubernetes restarts only Container A.
	Container B (in the same Pod) continues running unaffected.

	🔁 What does "restarted" mean?
	It does not recreate the Pod.
	It simply kills and restarts the failing container inside the same Pod, retaining:
	The same IP address
	The same volume mounts
	The same networking setup


# How do you configure log file sharing when one container writes logs and another container accesses them in the same pod?

✅ Use Case
One container (e.g., app-container) writes logs to a file.
Another container (e.g., log-agent) reads or ships those logs (like a sidecar).

✅ Solution: Use emptyDir Volume
emptyDir creates a temporary directory shared across containers in the same Pod.


# How do you confirm if the second container has access to the logs generated by the first container?
✅ 1. Use kubectl exec into the second container
Run this command to open a shell inside the second container (e.g., log-reader):

kubectl exec -it log-sharing-pod -c log-reader -- sh
✅ 2. List the shared log directory
Inside the second container's shell:
ls -l /var/log/app
You should see the log file (app.log) written by the first container.

✅ 3. Tail or read the log file
To confirm contents:
cat /var/log/app/app.log
or
tail -f /var/log/app/app.log
If logs are streaming, you’ll see the entries generated by the first container.



# How do you configure permissions to delete pods in k3s using RBAC?
To configure permissions to delete pods in k3s using RBAC (Role-Based Access Control), you need to:
Create a Role (or ClusterRole) that allows delete on pods.
Bind it to a ServiceAccount and role using RoleBinding (or ClusterRoleBinding).


# How do you write a script to delete completed pods in Kubernetes?
-> kubectl delete pod --all-namespaces \
  --field-selector=status.phase==Succeeded,status.phase==Failed

# How do you delete all pods in all states in a namespace or cluster-wide?
-> kubectl delete pods --all -n <namespace>

# What are StorageClasses in Kubernetes?
-> A StorageClass in Kubernetes defines how storage is provisioned dynamically for PersistentVolume(PV).

# A pod is CrashLoopBackOff. How do you troubleshoot?
-> I do run the kubectl describe pod <pod-name> -n <namespace> to idenitfy the error, mostly we get this CrashLoopBackOff due to 
   Non-zero exit code
   Image pulling issues
   Probe failures
   Volume mount or permission errors


# Your deployment is not scaling. What might be the reasons?
-> Resource limits on the nodes
-> Insufficient CPU/memory
-> Misconfigured HPA


# Network connectivity between pods is failing. How do you debug?
-> Check CNI plugin status
-> Ensure all pods are in same network space
-> Try to Ping or Curl Between Pods
   -> kubectl exec -it <source-pod> -n <namespace> -- ping <destination-pod-IP>
   -> kubectl exec -it <source-pod> -n <namespace> -- curl http://<destination-pod-IP>:<port>

#  Application is slow in Kubernetes. What areas do you check?
-> Pod resource limits and usage
-> Node health (kubectl get nodes)
-> Network latency (Istio, Cilium metrics)
-> Persistent storage I/O
-> Liveness/Readiness probes delaying traffic


# How would you implement blue-green deployment in Kubernetes?
Answer: Deploy both versions (blue and green) and use Services or Ingress to switch traffic. Can also use labels and selectors dynamically.

# How do you upgrade a Kubernetes cluster?
-> Monitor the logs and health post-upgrade
-> Use kubeadm upgrade plan (if using kubeadm)
-> Upgrade control plane first
-> Upgrade worker nodes one-by-one

# ETCD is unhealthy, and API server is timing out. Steps to recover?
-> Check etcd logs
-> Verify disk/storage health
-> Restore from etcd backup (etcdctl snapshot restore)
-> Restart control plane components

# You see high CPU usage in kubelet. What could be wrong?
-> Too many pods on a node
-> Frequent log rotation
-> Heavy resource metrics scraping (Prometheus)
-> Check logs, garbage collection, and kubelet flags
