# What is volumes in Kubernets
A volume's lifecycle is tied to the pod, not the individual containers. This means if a container crashes and is restarted, the volume will still retain its data.

# Types of Volumes:
Kubernetes supports various types of volumes, each with its own use cases, including:
-> emptyDir: A temporary directory that shares storage among containers in a pod.
-> hostPath: Mounts a file or directory from the host nodeâ€™s filesystem into a pod.
-> persistentVolumeClaim (PVC): A request for storage that dynamically provisions a persistent volume (PV) from a storage class.
-> nfs, awsElasticBlockStore, gcePersistentDisk, etc.: Integrate with external storage systems.

# What emptydir
-> When we use the emptydir volume type even if we restart and delete the pod we will lose the data assositate with pod.
-> We cant persistence and share data to multiple nodes    not recommand

# What hostpath
-> When we use the hostpath volume type even if we restart and delete the pod we will retrive the data assositate with pod. [means data will store in node whereever pod is running]
-> We cant persistence and share data to multiple nodes [It will save data in single node if that node will delete we will lose the data]  not recommand

Note: So far we dicussed above volume are ephemeral because if pod or nodes gets deleted or restared the data assosiate with pods those volumes gets deleted.

# What Persistene volumes
-> When we use the PVC volume type even if we restart and delete the pod we will retrive the data assositate with pod. [means data will store in node whereever pod is running]
-> We can persistence and share data to multiple nodes   [It will save data in multiple node if that node will delete we will retrive the data from another node]  recommand


# Kuberbets offers three components to persistence the data
-> Persistence volumes
-> Persistence volume claims
-> Storage class

# What is Persistence volumes(PV)
-> A PersistentVolume is a piece of storage in the Kubernetes cluster that has been provisioned by an administrator or dynamically provisioned using stoage class

# What is Persistence volume claims
-> A PersistentVolumeClaim is a request for storage by a user or developer.
-> It is a resource object in the Kubernetes API that allows a Pod to access a piece of storage from a PersistentVolume (PV).

# In persistence volume claim we have different access modes
-> ReadWriteMany   -> Which means this volume can be mounted as read write by many nodes  [If you are running in different node this is best option for you]
-> ReadWriteOnce   -> Which means all your pods are running in single node This is the best option [But you are pods running in different nodes they cant use this volumes
-> ReadOnlyOnce   ->  when use both ReadOnlyOnc and ReadOnlyMany you cant write the data in persistence volumes [it is just read only mode]
-> ReadOnlyMany   -> 
-> ReadWriteOncePod  -> When we use this access mode this volume can be mounted as read write once by single pod [ we will this mode to ensure only one pod accross the whole cluster can read or write]

# What is storage class 
-> How the pvs should be created dynamically

kubectl api-resources | grep storage    -> To get the api version  [false means storage class not created in any namespace those available to the entire cluster
kubectl get sc  -> to see storage class

-> Volumebinding mode means it will bind to pv immediatly
-> reclaimpolicy means whenever pvc delete automatically pv will aslo delete
-> retain means whenever pvc delete pv will not delete

# In persistence we can create two ways using EBS and EFS 
-> EBS will support only ReadWriteOnce   -> Which means all your pods are running in single node This is the best option [But you are pods running in different nodes they cant use this volumes
-> EFS will support only ReadWriteMany   -> Which means this volume can be mounted as read write by many nodes  [If you are running in different node this is best option for you]


# Amazon EBS (Elastic Block Store)
-> Access Mode: EBS volumes support ReadWriteOnce (RWO). This means:

An EBS volume can only be mounted as read-write by a single pod on one node at a time.
If you try to attach it to another pod (even on the same or a different node), it will fail.
Use Case: EBS is suitable for scenarios where you need a dedicated, high-performance storage option for a single application or pod. For example, if you have a database that requires persistent storage, EBS is a good fit since it offers fast, block-level storage.

# Amazon EFS (Elastic File System)
-> Access Mode: EFS supports ReadWriteMany (RWX). This means:

An EFS volume can be mounted by multiple pods across multiple nodes simultaneously.
This is ideal for applications that need shared access to the same data, such as web servers or applications that need to read/write to a common directory.
Use Case: EFS is suitable for scenarios where you need to share files between multiple pods or services. For example, if you have a set of microservices that need to access the same files or data, EFS allows them to do so concurrently.

Summary
EBS is best when you need dedicated storage for a single pod, providing high performance and reliability but not allowing sharing across multiple pods.

EFS is ideal for scenarios where multiple pods need to read and write to the same data simultaneously, enabling collaboration and shared access.

In summary, if your application architecture requires sharing data across multiple pods, you should use Amazon EFS. If you only need storage for a single pod, Amazon EBS is appropriate.


# Using EFS
-> First you create one EFS file in AWS
-> Click create filesystem, give file name, choose the VPC wherever your cluster is running
-> After create the files and click that, click network in below and click manage and choose the Security group on whichever SG yourc cluster is running and enable port number 2049
-> Finally you will use below pv and pvc in deployement

# To Install the EFS CSI Driver 
-> kubectl apply -k "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/ecr"

# pv.yml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: efs-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany  # Allows multiple pods to access the volume
  persistentVolumeReclaimPolicy: Retain
  storageClassName: efs-sc
  csi:
    driver: efs.csi.aws.com
    volumeHandle: fs-0ba7e1f0d3bb627f3  # Replace with your EFS file system ID

pvc.yml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: efs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
  storageClassName: efs-sc



# Data store with single node without using EBS 

# Install the AWS EBS CSI Driver Manually
-> helm repo update
-> kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/ecr"
-> kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-ebs-csi-driver   --> Verify Installation

vi pv.yml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: my-storage-class
  hostPath:
    path: /mnt/ravi  # Directory path on the host machine # This path automatically created in your workernode

Note: the above files working like as a host path means when delete the node the automatically data will be deleted.


vi pvc.yml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: yelp-camp-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
  storageClassName: my-storage-class    # Reference to your StorageClass


# This way is not working using EBS
-> Create one EBS volume

pv.yml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: ebs-sc
  csi:
    driver: ebs.csi.aws.com
    volumeHandle: vol-0e7bc9339916cc688  # Replace with your EBS volume ID or leave empty for dynamic provisioning


pvc.yml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: ebs-sc

Note: when i was using the above above data i am getting the below errors
Events:
  Type     Reason              Age                From                     Message
  ----     ------              ----               ----                     -------
  Normal   Scheduled           32s                default-scheduler        Successfully assigned default/my-app-deployment-74dfcdd97c-frwcq to ip-10-0-1-113.ec2.internal
  Warning  FailedAttachVolume  13s (x5 over 30s)  attachdetach-controller  AttachVolume.Attach failed for volume "my-pv" : volume attachment is being deleted

# Try with sc

sc.yml

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ebs-sc
provisioner: kubernetes.io/aws-ebs  # Ensure the correct provisioner
parameters:
  type: gp3  # Change to gp3 for better performance
  fsType: ext4


pv.yml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-new-pv  # Change the name to avoid conflict
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: ebs-sc
  csi:
    driver: ebs.csi.aws.com
    volumeHandle: vol-0e7bc9339916cc688  # Replace with your EBS volume ID

pvc.yml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: ebs-sc

Note: When i was using the above the data i am getting the below error
Events:
  Type     Reason              Age                     From                     Message
  ----     ------              ----                    ----                     -------
  Normal   Scheduled           3m26s                   default-scheduler        Successfully assigned default/my-app-deployment-74dfcdd97c-qr88f to ip-10-0-1-177.ec2.internal
  Warning  FailedAttachVolume  2m55s (x25 over 3m24s)  attachdetach-controller  AttachVolume.Attach failed for volume "my-new-pv" : rpc error: code = Internal desc = Could not attach volume "vol-0e7bc9339916cc688" to node "i-0253a3ba88e45c405": error listing AWS instances: operation error EC2: DescribeInstances, get identity: get credentials: failed to refresh cached credentials, no EC2 IMDS role found, operation error ec2imds: GetMetadata, failed to get rate limit token, retry quota exceeded, 0 available, 5 requested



# Why Use Volumes?
-> Data Persistence: Store data that needs to persist beyond the lifecycle of a pod.
-> Shared Storage: Enable multiple containers within a pod to share data.
-> Decoupling Storage from Pods: Manage storage independently from the pod lifecycle, making it easier to handle data.



https://youtu.be/LPy6Q-q1MVQ?si=PTgxiHXa-CimjB2Q
https://youtu.be/1qFMeAbVc-Y?si=0Vxuoujr8Whg79iN
