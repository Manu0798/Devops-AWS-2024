# What is terraform
-> Terraform is used to create the infrastructure as a code
-> Terraform is a open source software created by hashicrop
-> Go programming language is used to develop the terraform software
-> HashiCorp Configuration Language (HCL) we use to write the terraform code
-> Terrafrom supports the all cloud providers (AWS,Azure,GCP)

# What are the difference between Terrafrom and Ansible
Terraform
-> Terrafrom developed by hashicrop
-> Terrafrom is a infrastructure as a code. It means designed provision server themselves
-> It creating machines

Ansible
-> Ansible developed by REDHAT
-> Ansible is Configuration managnment tool. It means designed to install and manage the software on existing server
-> It installing softwares

# Components of terraform
-> Providers
-> Resources
-> Variables
-> Modules
-> Statefile
-> Backends
-> Provisioners
-> Data Source
-> Service Principals


# Providers 
-> Providers is used to help us to interact with our cloud platform

Ex:-
provider "aws" {
  region     = var.region
  access_key = var.access_key
  secret_key = var.secret_key
}

# How to setup the infrastructure in Multi region and Multi cloud platforms
# Multi Region provides
-> We have to create two providers blocks, within provides blocks we should use alias keyword to implement multi region infrastructure setup in terraform.

Ex:-
provider "aws" {
  alias = "us-east-1"
  region = "us-east-1"
}

provider "aws" {
  alias = "us-west-2"
  region = "us-west-2"
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
  provider = "aws.us-east-1"
}

resource "aws_instance" "example2" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
  provider = "aws.us-west-2"
}

# Multi Cloud provides
-> In the providers.tf file, define the AWS and Azure providers. we should create the resources for both AWS and Azure according their resources types.

Ex:-

provider "aws" {
  region = "us-east-1"
}

provider "azurerm" {
  subscription_id = "your-azure-subscription-id"
  client_id = "your-azure-client-id"
  client_secret = "your-azure-client-secret"
  tenant_id = "your-azure-tenant-id"
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
}

resource "azurerm_virtual_machine" "example" {
  name = "example-vm"
  location = "eastus"
  size = "Standard_A1"
}


# Required Provides
-> The Required Provides It allows us to specify the provider name, source, and version constraints

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 3.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = ">= 2.0, < 3.0"
    }
  }
}



# Resources 
-> Resources it help us to create infrastructure in cloud or AWS we deploy the resource
-> Resource are the most important element in the Terraform language.
-> Each resource block describes one or more infrastructure objects, such as virtual networks and compute instances.
Ex:-
resource "aws_vpc" "vpc" {
  cidr_block       = "10.0.0.0/16"
  instance_tenancy = "default"

  tags = {
    Name = "vpc01"
  }
}


# Variables 
-> Using variables in terraform configuration makes our deployment more dynamic.
-> We use varibles instaed of writing the hardcoded values in terraform
-> We have two types of varibles 
    Input variable  --> It pass the information to terraform
     Ex:-
        variable "region" {
          type    = string
          default = "ap-south-1"
        }
      
    Output variable  --> It Print the particular value
    Ex:-
      output "public_ip" {
      description = "Public IP address of the EC2 instance"
      value       = aws_instance.example_instance.public_ip
      }
-> A separate file with name variables.tf needs to be created in the working directory to store all variables for our used in main.tf configuration file.



# Modules  
-> It allows us to create group resources and reuse them across different projects or environments
-> Using modules we can deploy the code into multiple environments

ðŸŽ¯ Why use modules? or Advantages
Reusability: Write once, use in multiple places.
Organization: Clean, modular code.
Consistency: Same setup across environments (dev, prod, etc.)
Team collaboration: Easier for teams to work on specific parts.

Ex:-
module "module_test" {
  source = "./module"
}



# Statefile
-> Statefile is the heart of terraform. Terraform will store the information about our infrastructure that it has created
-> It compare the current state with desired state
-> terraform.tfstate file will create after you apply the terraform apply command

-> Disadvantages of Statefile
   -> It is sensitive file, it will store the even sensitive information about our infrastruture that it has created like access key, secreat keys

-> terraform show   --> This is command is use to show our statefile



-> How to restore the terraform.tfstate file
-> Terraform migration ( using import and then running terraform import command which will create a state file).
terraform import aws_vpc.vpc vpc-0108ace4a127ec01e
terraform import aws_subnet.public_1 subnet-055a4f5f5a08dda26
terraform import aws_subnet.public_2 subnet-04a6eb7ff81dbcd1b
terraform import aws_internet_gateway.igw igw-0852cce365a97faba
terraform import aws_route_table.rt1 rtb-0ac05e5322a112ec5
terraform import aws_route_table.rt2 rtb-09f39b59877f0af5c
terraform import aws_security_group.example_security_group sg-0d47b9681c32cfc33
terraform import aws_instance.example_instance i-0a039441365591418



# Backend and Restore the terraform.tfstate
-> The Backend block is use to work multiple people on same terraform code using terraform.tfstate file
-> If we use dynamodb state lock another persons wont able to work when one person working on code because it has locked
Ex:-
terraform {
  backend "s3" {
    bucket         = "manoj-9143"
    key            = "global/mystate/terraform.tfstate"
    region         = "ap-south-1"
    encrypt        = true
    dynamodb_table = "terraform-lock"
  }
}


resource "aws_dynamodb_table" "terraform_lock" {
  name           = "terraform-lock"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }
}


# Provisioners
-> Provisioners are used to execute and implemenent the actions during the infrastructure creation
-> we have three types of provisioners
   -> file Provisioner:- The file provisioner is used to copy files or directories from the local machine to a remote machine
      Ex:-
       provisioner "file" {
        source      = "local/path/to/localfile.txt"
        destination = "/path/on/remote/instance/file.txt"
        connection {
          type     = "ssh"
          user     = "ec2-user"
          private_key = file("~/.ssh/id_rsa")
        }
      }

   -> remote-exec Provisioner:- The remote-exec provisioner is used to run scripts or commands on a remote machine over SSH or WinRM connections
      Ex:-
       provisioner "remote-exec" {
          inline = [
            "sudo yum update -y",
            "sudo yum install -y httpd",
            "sudo systemctl start httpd",
          ]
        
          connection {
            type        = "ssh"
            user        = "ec2-user"
            private_key = file("~/.ssh/id_rsa")
            host        = aws_instance.example.public_ip
          }
        }

    -> local-exec Provisioner:- The local-exec provisioner is used to run scripts or commands locally on the machine where Terraform is executed
     Ex:-
      resource "null_resource" "example" {
        triggers = {
          always_run = "${timestamp()}"
        }
      
        provisioner "local-exec" {
          command = "echo 'This is a local command'"
        }
      }





# Data Source [you will use data source to get existing resource]
-> If you deploy your resource out of terraform and use them in your terraform code the way you use them through "Data Source"
-> Data source in terraform are used to get information about resource external to terraform and use them to setup your terrafrom resource
Ex:-
data "aws_vpc" "vpc" {
  cidr_block       = "10.0.0.0/16"
  instance_tenancy = "default"

  tags = {
    Name = "vpc01"
  }
}


# Terraform workspace (or) multiple env
-> when we use the workspace we can save our terraform.tfstate file in different env
-> Suppose you have two env one is dev env and another one is prod env
-> You should create dev workspaec before you deploy the dev env
     terraform workspace list   -> To show workspaces
     terraform workspace new dev  -> To create the dev workspace
     terraform workspace select dev  -> To switch the dev env
     terraform workspace show       -> To have the in which workspace you would being
     terraform apply -var-file dev.tfvars   -> To deploy the dev env



# Terraform locals
-> when we have local type resources it will the reducer length of reference ids
ex:-
locals {
  security = aws_security_group.example_security_group
  vpc_id      = aws_vpc.vpc.id
}

vpc_security_group_ids      = [local.security.id]
vpc_id = "${local.vpc_id.id}"
subnets = [local.cidr_block_Public_1, local.cidr_block_Public_2]
security = [local.security]

# Terraform function
-> It will combined and separate the words 

output "vpc_name" {
  value = join("",["${var.vpc_name}"],["RPM"])
}

output "vpc_name1" {
  value = lower(join("",["${var.vpc_name}"],["RPM"]))
}


# Terraform vault
-> Vault is a tool for managing secrets and sensitive data (like passwords, API keys, certificates, etc.). It allows you to store and access secrets securely, and manage access through policies.

-> There are a few ways to manage sensitive information in Terraform files. Here are some of the most common methods:
   -> sensitive attribute
   -> Secret management system
   -> Remote Backend
   -> Environment Variables


 2. Terraform drift detection ( if some one manually changed any settings for any resource, then detecting that change is called drift detection).

# There are 2 ways to detect it.

Scenario 1: Use terraform refresh using a cron job. ( terraform refresh, refershes the recents changes which was done manually to the statefile and keeps it updated.

Scenario 2: 

- A) Use audit/activity logs to see who made changes, if its changed by user and resources is managed by TF, then send an alert using lambda/azure functions and notify.

- B) Apply strict IAM rules so that no one can login to console.




You can see below link to know properly
https://youtu.be/_B7gtqwzKuc?si=sqI34qnTAZVnPnFy  
  
-> Terraform installation website
https://developer.hashicorp.com/terraform/install#linux

# How to install the terraform
sudo yum update -y
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform
terraform --version

# TO install terraform in ubuntu
-> sudo apt-get update
-> sudo apt-get install -y gnupg software-properties-common
-> sudo apt-get install -y gnupg software-properties-common
-> curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
-> sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com focal main"
-> sudo apt-get install terraform
-> terraform --version

# Terrafrom Commands
terraform init  -> This first command will initialize your working directory and download the necessary provider plugins.
terraform fmt      -> used to format your terraform configuration files into canonical format and style.
terraform validate   ->Check the syntax of terraform code
terraform plan   -> It compare the code with current state and desired state
terraform apply
terraform apply -auto-apporve
terraform destroy
terraform show   --> It will print the terraform.tfstate file in our terminal
terraform refresh  --> refershes the recents changes which was done manually to the statefile and keeps it updated.


# How to install terraform in windows
-> https://developer.hashicorp.com/terraform/install
-> Click on AMD64
-> Extract the file
-> you create one folder in you system and copy terraform in that folder and paste the file in created folder
-> after copy the that address and go env and click path and add new and past that path there
-> Later on open the cmd and check the wheather terraform install or not
terraform -version


# Install AWS CLI on Amazon linux
-> Install AWS CLI in your instance
-> How to install AWSCLI
sudo yum update -y
sudo yum install python3-pip -y
sudo pip3 install awscli
aws --version
-> Create Secret key In IAM
aws configure
aws sts get-caller-identity

# How to install AWS cli in windows
-> https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
-> https://awscli.amazonaws.com/AWSCLIV2.msi
aws --version

# How to install AWS-CLI on ubuntu
-> sudo apt-get update
-> sudo apt-get install -y curl unzip
-> curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
-> unzip awscliv2.zip
-> sudo ./aws/install
-> aws --version
-> Create Secret key In IAM
aws configure
aws sts get-caller-identity


# Terraform commands
-> terraform init
-> terraform fmt
-> terraform validate
-> terraform plan -var-file="accounts/stag/terraform.tfvars"
-> terraform apply -var-file="accounts/stag/terraform.tfvars"

# For backend s3
-> terraform init -backend-config="accounts/stag/backend.tfvars"

# For destoring 
-> terraform init -migrate-state
-> terraform destroy -var-file="accounts/stag/terraform.tfvars"


-> terraform init -reconfigure `  -backend-config="bucket=frissly-uat-tfstate" `   -backend-config="key=pipeline/terraform.tfstate" `  -backend-config="region=ap-south-1" `  -backend-config="encrypt=true" ` -backend-config="use_lockfile=true"
